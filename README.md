# Bachelorarbeit â€“ Spark Memory Optimization for Graph Workloads

Dieses Repository enthÃ¤lt den Quellcode und experimentelle Ergebnisse meiner Bachelorarbeit mit dem Titel:

**â€Optimizing Apache Spark Memory Configuration for Efficient Execution of Graph Workloadsâ€œ**

Ziel der Arbeit ist es, das Speicherverhalten von Graph-Algorithmen (z.â€¯B. PageRank, Connected Components) in Apache Spark (GraphX) zu analysieren und Optimierungspotenziale bei verschiedenen Speicherparametern aufzudecken.

---

## ğŸ“ Projektstruktur

```
.
â”œâ”€â”€ Main.scala   # Hauptprogramm zum AusfÃ¼hren von Graph-Algorithmen
â”œâ”€â”€ build.sbt                    # Scala-Build-Konfiguration
â”œâ”€â”€ data/                        # BeispieldatensÃ¤tze (z.â€¯B. web-Google.txt)
â”œâ”€â”€ results/                     # Logs, Output-Daten und Diagramme
â”œâ”€â”€ scripts/                     # Bash- oder Python-Skripte zur Automatisierung
â””â”€â”€ README.md                    # Diese Datei
```

---

## ğŸš€ Schnellstart

### Voraussetzungen

- Java 8 oder 11
- Scala 2.12.x
- sbt (Scala Build Tool)
- Apache Spark 3.x

### Lokales AusfÃ¼hren

```bash
sbt run
```

Mit Parametern (Dateipfad + Algorithmus):

```bash
sbt "run web-Google.txt pagerank"
```

Dies lÃ¤dt die Datei `web-Google.txt` als Kantenliste und startet z.â€¯B. PageRank.

---

## ğŸ“Š Forschungsfokus

- **Speicherverhalten** unter verschiedenen Spark-Konfigurationen:
    - `spark.memory.fraction`
    - `executor.memory`
    - `storageLevel` (z.â€¯B. MEMORY_ONLY vs. MEMORY_AND_DISK)
- **Graphcharakteristika**, die Speicherbedarf beeinflussen (z.â€¯B. Knotenzahl, Gradverteilung)
- **Laufzeit- und GC-Analysen**

Tests erfolgen lokal und auf dem Cluster auf der Google Cloud Platform.

---


## ğŸ‘¤ Autor

**Nguyen Duc Rohr**  
TU Berlin â€“ Bachelorarbeit DOS, 2025  
[GitHub @SnenzZ](https://github.com/SnenzZ)

